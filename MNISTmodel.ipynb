{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "#!tar -zxvf MNIST.tar.gz\n",
    "dataset = data.MNIST(root = '/home/anmol/Programming/python/Deep Learning/')#,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = data.MNIST(root='/home/anmol/Programming/python/Deep Learning/', train=False)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x7FD3A90B80D0>, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "image, label = dataset[0]\n",
    "plt.imshow(image, cmap='gray')\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch datasets allow us to specify one or more transformation functions that are applied to the images as they are loaded. The `torchvision.transforms` module contains many such predefined functions. We'll use the `ToTensor` transform to convert images into PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset (images and labels)\n",
    "dataset = data.MNIST(root='/home/anmol/Programming/python/Deep Learning/', \n",
    "                train=True,\n",
    "                transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n",
      "tensor([[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
      "        [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
      "        [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
      "        [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
      "        [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]])\n",
      "tensor(1.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "img_tensor, label = dataset[0]\n",
    "print(img_tensor.shape, label)\n",
    "print(img_tensor[0,10:15,10:15])\n",
    "print(torch.max(img_tensor), torch.min(img_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values range from 0 to 1, with `0` representing black, `1` white, and the values in between different shades of grey. We can also plot the tensor as an image using `plt.imshow`.\n",
    "## Training and Validation Datasets\n",
    "\n",
    "While building real-world machine learning models, it is quite common to split the dataset into three parts:\n",
    "\n",
    "1. **Training set** - used to train the model, i.e., compute the loss and adjust the model's weights using gradient descent.\n",
    "2. **Validation set** - used to evaluate the model during training, adjust hyperparameters (learning rate, etc.), and pick the best version of the model.\n",
    "3. **Test set** - used to compare different models or approaches and report the model's final accuracy.\n",
    "\n",
    "In the MNIST dataset, there are 60,000 training images and 10,000 test images. The test set is standardized so that different researchers can report their models' results against the same collection of images. \n",
    "\n",
    "Since there's no predefined validation set, we must manually split the 60,000 images into training and validation datasets. Let's set aside 10,000 randomly chosen images for validation. We can do this using the `random_spilt` method from PyTorch.\n",
    "\n",
    "## Model\n",
    "\n",
    "Now that we have prepared our data loaders, we can define our model.\n",
    "\n",
    "* A **logistic regression** model is almost identical to a linear regression model. It contains weights and bias matrices, and the output is obtained using simple matrix operations (`pred = x @ w.t() + b`). \n",
    "\n",
    "* As we did with linear regression, we can use `nn.Linear` to create the model instead of manually creating and initializing the matrices.\n",
    "\n",
    "* Since `nn.Linear` expects each training example to be a vector, each `1x28x28` image tensor is _flattened_ into a vector of size 784 `(28*28)` before being passed into the model. \n",
    "\n",
    "* The output for each image is a vector of size 10, with each element signifying the probability of a particular target label (i.e., 0 to 9). The predicted label for an image is simply the one with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [50000, 10000])\n",
    "len(train_ds), len(val_ds)\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0201,  0.0149, -0.0327,  0.0307, -0.0070,  0.0116, -0.0180,  0.0069,\n",
       "         0.0080,  0.0132], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "# Logistic regression model\n",
    "model = nn.Linear(input_size, num_classes)\n",
    "print(model.weight.shape)\n",
    "model.weight\n",
    "print(model.bias.shape)\n",
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 6, 8, 4, 7, 4, 8, 4, 8, 7, 6, 3, 8, 1, 6, 9, 2, 5, 5, 8, 7, 7, 9,\n",
      "        2, 2, 4, 8, 2, 4, 3, 2, 3, 8, 8, 0, 5, 3, 8, 2, 3, 9, 6, 8, 6, 8, 6, 4,\n",
      "        1, 2, 9, 0, 7, 7, 0, 9, 9, 3, 0, 3, 5, 6, 8, 6, 5, 6, 3, 6, 6, 0, 5, 3,\n",
      "        0, 6, 3, 8, 5, 5, 4, 5, 6, 0, 1, 3, 8, 9, 3, 6, 0, 2, 3, 9, 3, 9, 1, 2,\n",
      "        3, 0, 7, 1, 0, 7, 7, 8, 8, 4, 5, 2, 8, 8, 1, 7, 8, 5, 7, 6, 2, 9, 0, 0,\n",
      "        0, 0, 0, 9, 4, 6, 5, 1])\n",
      "torch.Size([128, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-72d13a104bd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x10)"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(labels)\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    print(outputs)\n",
    "    break\n",
    "# gives error as nn.Linear expects input in form of a vector so flattening out the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 784])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.reshape(128, 784).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the `__init__` constructor method, we instantiate the weights and biases using `nn.Linear`. And inside the `forward` method, which is invoked when we pass a batch of inputs to the model, we flatten the input tensor and pass it into `self.linear`.\n",
    "\n",
    "`xb.reshape(-1, 28*28)` indicates to PyTorch that we want a *view* of the `xb` tensor with two dimensions. The length along the 2nd dimension is 28\\*28 (i.e., 784). One argument to `.reshape` can be set to `-1` (in this case, the first dimension) to let PyTorch figure it out automatically based on the shape of the original tensor.\n",
    "\n",
    "Note that the model no longer has `.weight` and `.bias` attributes (as they are now inside the `.linear` attribute), but it does have a `.parameters` method that returns a list containing the weights and bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0041,  0.0065, -0.0351,  ..., -0.0276,  0.0328,  0.0285],\n",
       "         [-0.0182, -0.0087,  0.0248,  ..., -0.0147,  0.0225,  0.0355],\n",
       "         [-0.0197, -0.0116, -0.0154,  ..., -0.0201, -0.0029, -0.0202],\n",
       "         ...,\n",
       "         [-0.0101,  0.0256, -0.0085,  ...,  0.0231,  0.0227,  0.0208],\n",
       "         [-0.0278, -0.0234,  0.0248,  ..., -0.0306, -0.0044, -0.0224],\n",
       "         [ 0.0165, -0.0198,  0.0352,  ...,  0.0242, -0.0055, -0.0234]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0156,  0.0127, -0.0310,  0.0218,  0.0327, -0.0150,  0.0004, -0.0219,\n",
       "         -0.0335,  0.0116], requires_grad=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear\n",
    "print(model.linear.weight.shape, model.linear.bias.shape)\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "outputs.shape :  torch.Size([128, 10])\n",
      "Sample outputs :\n",
      " tensor([[ 0.1327,  0.3282,  0.0398, -0.2392, -0.0270, -0.0917,  0.0086,  0.1188,\n",
      "         -0.0321, -0.1197],\n",
      "        [ 0.0111,  0.2735, -0.1232, -0.0434, -0.0999,  0.0718,  0.0142, -0.2897,\n",
      "         -0.2042, -0.0203]])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    break\n",
    "\n",
    "print('outputs.shape : ', outputs.shape)\n",
    "print('Sample outputs :\\n', outputs[:2].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the 100 input images, we get 10 outputs, one for each class. As discussed earlier, we'd like these outputs to represent probabilities. Each output row's elements must lie between 0 to 1 and add up to 1, which is not the case. \n",
    "\n",
    "To convert the output rows into probabilities, we use the softmax function, which has the following formula:\n",
    "\n",
    "![softmax](https://i.imgur.com/EAh9jLN.png)\n",
    "\n",
    "First, we replace each element `yi` in an output row by `e^yi`, making all the elements positive. \n",
    "\n",
    "![](https://www.montereyinstitute.org/courses/DevelopmentalMath/COURSE_TEXT2_RESOURCE/U18_L1_T1_text_final_6_files/image001.png)\n",
    "\n",
    "\n",
    "\n",
    "Then, we divide them by their sum to ensure that they add up to 1. The resulting vector can thus be interpreted as probabilities.\n",
    "\n",
    "While it's easy to implement the softmax function (you should try it!), we'll use the implementation that's provided within PyTorch because it works well with multidimensional tensors (a list of output rows in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample probabilities:\n",
      " tensor([[0.1116, 0.1357, 0.1017, 0.0769, 0.0951, 0.0891, 0.0986, 0.1100, 0.0946,\n",
      "         0.0867],\n",
      "        [0.1042, 0.1355, 0.0911, 0.0987, 0.0932, 0.1107, 0.1045, 0.0771, 0.0840,\n",
      "         0.1010]])\n",
      "Sum:  1.0\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "outputs[:2]\n",
    "# Apply softmax for each output row\n",
    "probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "# Look at sample probabilities\n",
    "print(\"Sample probabilities:\\n\", probs[:2].data)\n",
    "\n",
    "# Add up the probabilities of an output row\n",
    "print(\"Sum: \", torch.sum(probs[0]).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can determine the predicted label for each image by simply choosing the index of the element with the highest probability in each output row. We can do this using `torch.max`, which returns each row's largest element and the corresponding index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 5, 1, 6, 1, 4, 1, 1, 6, 1, 1, 1,\n",
      "        1, 1, 6, 5, 6, 1, 1, 1, 1, 3, 1, 1, 4, 1, 1, 0, 5, 2, 1, 1, 1, 1, 1, 1,\n",
      "        4, 1, 1, 1, 0, 6, 3, 1, 1, 1, 1, 0, 1, 3, 0, 1, 1, 0, 1, 6, 1, 6, 6, 1,\n",
      "        1, 1, 4, 1, 1, 2, 1, 1, 1, 1, 3, 5, 5, 5, 1, 9, 1, 1, 6, 6, 1, 1, 1, 1,\n",
      "        4, 6, 1, 0, 2, 1, 1, 2, 1, 1, 5, 1, 1, 5, 6, 3, 1, 4, 1, 6, 1, 1, 1, 5,\n",
      "        1, 1, 1, 1, 6, 1, 1, 4])\n",
      "tensor([0.1357, 0.1355, 0.1262, 0.1861, 0.1614, 0.1249, 0.1515, 0.1453, 0.1326,\n",
      "        0.1478, 0.1180, 0.1348, 0.1446, 0.1252, 0.1693, 0.1143, 0.1169, 0.1208,\n",
      "        0.1468, 0.1117, 0.1231, 0.1563, 0.1449, 0.1513, 0.1301, 0.1425, 0.1291,\n",
      "        0.1247, 0.1170, 0.1402, 0.1385, 0.1253, 0.1908, 0.1200, 0.1461, 0.1600,\n",
      "        0.1254, 0.1281, 0.1530, 0.1316, 0.1647, 0.1206, 0.1574, 0.1262, 0.1360,\n",
      "        0.1482, 0.1373, 0.1303, 0.1572, 0.1167, 0.1401, 0.1109, 0.1484, 0.1421,\n",
      "        0.1276, 0.1400, 0.1136, 0.1196, 0.1396, 0.1268, 0.1250, 0.1300, 0.1203,\n",
      "        0.1491, 0.1389, 0.1339, 0.1595, 0.1343, 0.1606, 0.1176, 0.1260, 0.1243,\n",
      "        0.1348, 0.1619, 0.1132, 0.1365, 0.1374, 0.1279, 0.1274, 0.1381, 0.1178,\n",
      "        0.1326, 0.1221, 0.1452, 0.1450, 0.1204, 0.1344, 0.1159, 0.1455, 0.1308,\n",
      "        0.1172, 0.1370, 0.1179, 0.1296, 0.1228, 0.1393, 0.1253, 0.1345, 0.1335,\n",
      "        0.1245, 0.1265, 0.1625, 0.1216, 0.1346, 0.1481, 0.1269, 0.1465, 0.1268,\n",
      "        0.1333, 0.1189, 0.1360, 0.1247, 0.1394, 0.1354, 0.1500, 0.1176, 0.1211,\n",
      "        0.1264, 0.1433, 0.1128, 0.1556, 0.1511, 0.1167, 0.1195, 0.1118, 0.1323,\n",
      "        0.1530, 0.1193], grad_fn=<MaxBackward0>)\n",
      "labels tensor([[0, 0, 0,  ..., 0, 1, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 1, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 1],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 1, 0, 0]])\n",
      "after one-hot encoding tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "max_probs, preds = torch.max(probs, dim=1)\n",
    "print(preds)\n",
    "print(max_probs)\n",
    "print('labels',labels)\n",
    "labels = F.one_hot(labels,num_classes=10)\n",
    "print(\"after one-hot encoding\",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0941, 0.0930, 0.0968,  ..., 0.1271, 0.0989, 0.1290],\n",
       "        [0.1422, 0.0835, 0.0921,  ..., 0.1304, 0.0869, 0.1138],\n",
       "        [0.0943, 0.1342, 0.0870,  ..., 0.1011, 0.1156, 0.1061],\n",
       "        ...,\n",
       "        [0.0829, 0.1129, 0.0733,  ..., 0.1215, 0.0849, 0.1381],\n",
       "        [0.1011, 0.1141, 0.1155,  ..., 0.0977, 0.1062, 0.1171],\n",
       "        [0.0874, 0.0914, 0.1025,  ..., 0.1525, 0.0887, 0.1283]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(outputs, labels)\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is an excellent way for us (humans) to evaluate the model. However, we can't use it as a loss function for optimizing our model using gradient descent for the following reasons:\n",
    "\n",
    "1. It's not a differentiable function. `torch.max` and `==` are both non-continuous and non-differentiable operations, so we can't use the accuracy for computing gradients w.r.t the weights and biases.\n",
    "\n",
    "2. It doesn't take into account the actual probabilities predicted by the model, so it can't provide sufficient feedback for incremental improvements. \n",
    "\n",
    "For these reasons, accuracy is often used as an **evaluation metric** for classification, but not as a loss function. A commonly used loss function for classification problems is the **cross-entropy**, which has the following formula:\n",
    "\n",
    "![cross-entropy](https://i.imgur.com/VDRDl1D.png)\n",
    "\n",
    "While it looks complicated, it's actually quite simple:\n",
    "\n",
    "* For each output row, pick the predicted probability for the correct label. E.g., if the predicted probabilities for an image are `[0.1, 0.3, 0.2, ...]` and the correct label is `1`, we pick the corresponding element `0.3` and ignore the rest.\n",
    "\n",
    "* Then, take the [logarithm](https://en.wikipedia.org/wiki/Logarithm) of the picked probability. If the probability is high, i.e., close to 1, then its logarithm is a very small negative value, close to 0. And if the probability is low (close to 0), then the logarithm is a very large negative value. We also multiply the result by -1, which results is a large postive value of the loss for poor predictions.\n",
    "\n",
    "![](https://www.intmath.com/blog/wp-content/images/2019/05/log10.png)\n",
    "\n",
    "* Finally, take the average of the cross entropy across all the output rows to get the overall loss for a batch of data.\n",
    "\n",
    "Unlike accuracy, cross-entropy is a continuous and differentiable function. It also provides useful feedback for incremental improvements in the model (a slightly higher probability for the correct label leads to a lower loss). These two factors make cross-entropy a better choice for the loss function.\n",
    "\n",
    "As you might expect, PyTorch provides an efficient and tensor-friendly implementation of cross-entropy as part of the `torch.nn.functional` package. Moreover, it also performs softmax internally, so we can directly pass in the model's outputs without converting them into probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3031, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "outputs\n",
    "loss_fn = F.cross_entropy\n",
    "# Loss for current batch of data\n",
    "loss = loss_fn(outputs, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Now that we have defined the data loaders, model, loss function and optimizer, we are ready to train the model. The training process is identical to linear regression, with the addition of a \"validation phase\" to evaluate the model in each epoch. Here's what it looks like in pseudocode:\n",
    "\n",
    "```\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    for batch in train_loader:\n",
    "        # Generate predictions\n",
    "        # Calculate loss\n",
    "        # Compute gradients\n",
    "        # Update weights\n",
    "        # Reset gradients\n",
    "    \n",
    "    # Validation phase\n",
    "    for batch in val_loader:\n",
    "        # Generate predictions\n",
    "        # Calculate loss\n",
    "        # Calculate metrics (accuracy etc.)\n",
    "    # Calculate average validation loss & metrics\n",
    "    \n",
    "    # Log epoch, loss & metrics for inspection\n",
    "```\n",
    "\n",
    "Some parts of the training loop are specific the specific problem we're solving (e.g. loss function, metrics etc.) whereas others are generic and can be applied to any deep learning problem. \n",
    "\n",
    "We'll include the problem-independent parts within a function called `fit`, which will be used to train the model. The problem-specific parts will be implemented by adding new methods to the `nn.Module` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gradient descent as the optimiser\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    history = [] # for recording epoch-wise results in validation data\n",
    "    history_train = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        #result = evaluate(model,train_loader)\n",
    "        #model.epoch_end(epoch, result)\n",
    "        #history_train.append(result)\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "\n",
    "    return history,history_train\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader] # batch-wise validation_step method is used from MnistModel class\n",
    "    return model.validation_epoch_end(outputs) # epoch values are generated using validation_epoch_end method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finally, let's redefine the `MnistModel` class to include additional methods `training_step`, `validation_step`, `validation_epoch_end`, and `epoch_end` used by `fit` and `evaluate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-defining MnistModel class to include more methods\n",
    "class MnistModel(nn.Module):\n",
    "    # CHANGING THIS TO A PROPER  Neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784) #reshaping input (flatenning it out)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \"\"\"\n",
    "    def __init__(self,in_size,out_size):\n",
    "        super().__init__()\n",
    "        # hidden layer 1\n",
    "        self.layer1 = nn.Linear(in_size,64)\n",
    "        # hidden layer 2\n",
    "        self.layer2 = nn.Linear(64,128)\n",
    "        # hidden layer 3\n",
    "        self.layer3 = nn.Linear(128,64)\n",
    "        # output layer\n",
    "        self.layer4 = nn.Linear(64,out_size)\n",
    "        \n",
    "    def forward(self,xb):\n",
    "        out = xb.view(xb.size(0),-1)\n",
    "        out = self.layer1(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.layer3(out)\n",
    "        out = torch.relu(out)\n",
    "        out = self.layer4(out)\n",
    "        #print('before softmax',out)\n",
    "        #out = torch.softmax(out,dim=0)\n",
    "        #print('after applying softmax',out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):   # operation on a batch of input\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "    \n",
    "model = MnistModel(in_size= 784,out_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.3026037216186523, 'val_acc': 0.13043908774852753}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0 = evaluate(model, val_loader)\n",
    "result0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial accuracy is around 10%, which one might expect from a randomly initialized model (since it has a 1 in 10 chance of getting a label right by guessing randomly).\n",
    "\n",
    "We are now ready to train the model. Let's train for five epochs and look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.4271, val_acc: 0.8658\n",
      "Epoch [1], val_loss: 0.2749, val_acc: 0.9154\n",
      "Epoch [2], val_loss: 0.2026, val_acc: 0.9398\n",
      "Epoch [3], val_loss: 0.1796, val_acc: 0.9432\n",
      "Epoch [4], val_loss: 0.1459, val_acc: 0.9557\n"
     ]
    }
   ],
   "source": [
    "history1 = fit(5, 0.1, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.1249, val_acc: 0.9629\n",
      "Epoch [1], val_loss: 0.1200, val_acc: 0.9647\n",
      "Epoch [2], val_loss: 0.1179, val_acc: 0.9641\n",
      "Epoch [3], val_loss: 0.1139, val_acc: 0.9659\n",
      "Epoch [4], val_loss: 0.1103, val_acc: 0.9657\n",
      "Epoch [0], val_loss: 0.1040, val_acc: 0.9687\n",
      "Epoch [1], val_loss: 0.1033, val_acc: 0.9693\n",
      "Epoch [2], val_loss: 0.1027, val_acc: 0.9696\n",
      "Epoch [3], val_loss: 0.1023, val_acc: 0.9692\n",
      "Epoch [4], val_loss: 0.1009, val_acc: 0.9691\n",
      "Epoch [0], val_loss: 0.1008, val_acc: 0.9689\n",
      "Epoch [1], val_loss: 0.1009, val_acc: 0.9687\n",
      "Epoch [2], val_loss: 0.1007, val_acc: 0.9686\n",
      "Epoch [3], val_loss: 0.1007, val_acc: 0.9692\n",
      "Epoch [4], val_loss: 0.1006, val_acc: 0.9689\n"
     ]
    }
   ],
   "source": [
    "history2 = fit(5, 0.05, model, train_loader, val_loader)\n",
    "history3 = fit(5, 0.01, model, train_loader, val_loader)\n",
    "history4 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.0998, val_acc: 0.9693\n",
      "Epoch [1], val_loss: 0.0998, val_acc: 0.9696\n",
      "Epoch [2], val_loss: 0.0997, val_acc: 0.9698\n",
      "Epoch [3], val_loss: 0.0997, val_acc: 0.9696\n",
      "Epoch [4], val_loss: 0.0996, val_acc: 0.9698\n",
      "Epoch [5], val_loss: 0.0996, val_acc: 0.9696\n",
      "Epoch [6], val_loss: 0.0997, val_acc: 0.9696\n",
      "Epoch [7], val_loss: 0.0996, val_acc: 0.9699\n",
      "Epoch [8], val_loss: 0.0996, val_acc: 0.9693\n",
      "Epoch [9], val_loss: 0.0994, val_acc: 0.9698\n",
      "Epoch [10], val_loss: 0.0994, val_acc: 0.9698\n",
      "Epoch [11], val_loss: 0.0995, val_acc: 0.9696\n",
      "Epoch [12], val_loss: 0.0995, val_acc: 0.9701\n",
      "Epoch [13], val_loss: 0.0994, val_acc: 0.9700\n",
      "Epoch [14], val_loss: 0.0993, val_acc: 0.9699\n",
      "Epoch [15], val_loss: 0.0992, val_acc: 0.9698\n",
      "Epoch [16], val_loss: 0.0992, val_acc: 0.9698\n",
      "Epoch [17], val_loss: 0.0993, val_acc: 0.9697\n",
      "Epoch [18], val_loss: 0.0992, val_acc: 0.9700\n",
      "Epoch [19], val_loss: 0.0993, val_acc: 0.9698\n",
      "Epoch [20], val_loss: 0.0993, val_acc: 0.9701\n",
      "Epoch [21], val_loss: 0.0995, val_acc: 0.9695\n",
      "Epoch [22], val_loss: 0.0992, val_acc: 0.9701\n",
      "Epoch [23], val_loss: 0.0991, val_acc: 0.9700\n",
      "Epoch [24], val_loss: 0.0992, val_acc: 0.9702\n"
     ]
    }
   ],
   "source": [
    "history5 = fit(25, 0.001, model, train_loader, val_loader)\n",
    "history = history1 + history2 + history3 + history4 +history5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's quite clear from the above picture that the model probably won't cross the accuracy threshold of 90% even after training for a very long time. One possible reason for this is that the learning rate might be too high. The model's parameters may be \"bouncing\" around the optimal set of parameters for the lowest loss. You can try reducing the learning rate and training for a few more epochs to see if it helps.\n",
    "\n",
    "The more likely reason that **the model just isn't powerful enough**. If you remember our initial hypothesis, we have assumed that the output (in this case the class probabilities) is a **linear function** of the input (pixel intensities), obtained by perfoming a matrix multiplication with the weights matrix and adding the bias. This is a fairly weak assumption, as there may not actually exist a linear relationship between the pixel intensities in an image and the digit it represents. While it works reasonably well for a simple dataset like MNIST (getting us to 85% accuracy), we need more sophisticated models that can capture non-linear relationships between image pixels and labels for complex tasks like recognizing everyday objects, animals etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test dataset\n",
    "test_dataset = data.MNIST(root='/home/anmol/Programming/python/Deep Learning/', \n",
    "                     train=False,\n",
    "                     transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([1, 28, 28])\n",
      "Label: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Shape:', img.shape)\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`img.unsqueeze` simply adds another dimension at the begining of the 1x28x28 tensor, making it a 1x1x28x28 tensor, which the model views as a batch containing a single image.\n",
    "\n",
    "Let's try it out with a few images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7 , Predicted: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0 , Predicted: 0\n",
      "Label: 9 , Predicted: 9\n",
      "Label: 2 , Predicted: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[10]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))\n",
    "img, label = test_dataset[193]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))\n",
    "img, label = test_dataset[1839]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.09204165637493134, 'val_acc': 0.97265625}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "result = evaluate(model, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mnist-logistic.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.state_dict` method returns an `OrderedDict` containing all the weights and bias matrices mapped to the right attributes of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight',\n",
       "              tensor([[-2.3459e-02, -2.5167e-02, -1.3336e-02,  ...,  9.3090e-03,\n",
       "                       -8.1156e-03, -3.1615e-02],\n",
       "                      [ 2.5964e-02,  1.8885e-02, -1.0100e-02,  ..., -2.6874e-02,\n",
       "                       -1.9925e-03, -2.9954e-02],\n",
       "                      [ 1.6361e-02,  3.3987e-02,  2.3278e-02,  ..., -3.7107e-03,\n",
       "                       -1.3555e-02,  2.9773e-02],\n",
       "                      ...,\n",
       "                      [-1.7228e-03, -3.4604e-02, -2.2041e-02,  ..., -3.1494e-02,\n",
       "                       -7.4112e-03,  1.4982e-02],\n",
       "                      [ 9.8619e-03,  2.1688e-02, -1.4468e-02,  ..., -3.1331e-02,\n",
       "                        2.0164e-02, -2.7014e-02],\n",
       "                      [ 2.0179e-02,  8.3857e-03,  3.0747e-02,  ..., -2.3913e-02,\n",
       "                        1.9141e-02,  6.7008e-05]])),\n",
       "             ('layer1.bias',\n",
       "              tensor([ 0.0790,  0.1563,  0.0182,  0.0471,  0.0198,  0.0262,  0.0133, -0.0519,\n",
       "                       0.0567, -0.1144,  0.0997,  0.0380,  0.0350,  0.1254,  0.0395,  0.0560,\n",
       "                      -0.1135,  0.0580,  0.0574, -0.0053, -0.0598, -0.0211,  0.0010,  0.1234,\n",
       "                       0.0870,  0.0373, -0.0268,  0.1492,  0.0037, -0.0125, -0.0860, -0.0113,\n",
       "                       0.0726, -0.0677,  0.1116,  0.1071,  0.1234,  0.0885,  0.0342, -0.0230,\n",
       "                       0.0653,  0.0352,  0.0790, -0.0215,  0.0351, -0.0636, -0.0395,  0.0199,\n",
       "                       0.0391,  0.0373, -0.0850,  0.0151, -0.0320,  0.0026,  0.0461,  0.0289,\n",
       "                       0.0128,  0.0341, -0.0201,  0.0372,  0.1353, -0.0057,  0.1090,  0.0227])),\n",
       "             ('layer2.weight',\n",
       "              tensor([[-0.0482, -0.0803,  0.0721,  ...,  0.0541,  0.0147, -0.1178],\n",
       "                      [ 0.1596,  0.0716, -0.1173,  ...,  0.0013, -0.2655,  0.0814],\n",
       "                      [-0.0952,  0.1057,  0.0596,  ...,  0.0667,  0.1173,  0.0501],\n",
       "                      ...,\n",
       "                      [ 0.0940,  0.2433,  0.0708,  ..., -0.0504, -0.2593, -0.0340],\n",
       "                      [ 0.1070,  0.0626, -0.0330,  ...,  0.0595,  0.0929,  0.0036],\n",
       "                      [ 0.0433, -0.1201,  0.0780,  ...,  0.0312,  0.0339,  0.1490]])),\n",
       "             ('layer2.bias',\n",
       "              tensor([ 6.3138e-02,  1.2947e-01,  2.0548e-06, -7.9265e-02,  8.7728e-02,\n",
       "                       1.9693e-01, -7.0496e-02,  1.7459e-01,  1.2692e-01,  5.9111e-02,\n",
       "                       5.4189e-02,  2.0060e-01,  5.9653e-02, -5.4732e-02,  7.4344e-02,\n",
       "                       9.9629e-02, -5.5088e-02, -5.4428e-02,  1.0466e-01, -9.5524e-02,\n",
       "                       2.1197e-01, -6.4483e-02, -9.1942e-02, -1.1965e-01,  1.6091e-01,\n",
       "                      -8.7256e-02,  2.2085e-01,  4.7408e-02,  1.4413e-01,  1.8192e-01,\n",
       "                       5.0754e-02, -5.1678e-02, -9.7855e-02, -6.3957e-04, -2.7292e-02,\n",
       "                       1.9496e-01, -9.0403e-02,  1.0829e-01,  1.1909e-01,  2.2725e-02,\n",
       "                       5.7231e-02,  2.2260e-01,  7.5807e-02,  2.4932e-02, -8.1979e-03,\n",
       "                       1.7837e-01,  6.2512e-02, -1.0554e-01,  1.0209e-01, -4.0893e-02,\n",
       "                      -1.2387e-01,  6.1262e-02, -8.7062e-02, -7.2018e-02, -1.9004e-02,\n",
       "                       7.6847e-02, -2.6832e-02,  1.8247e-01, -2.2617e-02,  7.1025e-02,\n",
       "                      -8.3564e-02, -8.8139e-02,  1.0731e-01, -2.4809e-02,  7.7287e-02,\n",
       "                       5.2360e-02,  1.1463e-01, -8.6447e-02,  5.3323e-02, -6.6972e-03,\n",
       "                       1.3223e-01,  4.6195e-02,  1.5549e-01,  1.3349e-01,  9.1412e-02,\n",
       "                       5.2547e-02,  5.5083e-02, -2.4410e-03, -8.7060e-02,  6.2185e-02,\n",
       "                       2.6385e-02, -7.2018e-02, -1.0661e-02, -1.2268e-01, -7.8083e-02,\n",
       "                       1.0153e-01, -1.6177e-02, -5.5704e-02, -1.2511e-01,  2.4543e-02,\n",
       "                      -8.9496e-02,  2.2529e-01,  1.1736e-01,  3.0772e-02, -7.3083e-03,\n",
       "                       1.8485e-01,  1.1401e-01,  8.0980e-03,  8.0593e-02, -6.5494e-03,\n",
       "                      -2.4675e-02,  4.4232e-02,  7.7082e-02,  1.8283e-01,  5.6075e-02,\n",
       "                      -1.1253e-01,  4.4395e-02,  1.5240e-02,  7.4724e-02,  6.8421e-02,\n",
       "                       1.7918e-01, -3.9094e-02, -5.4107e-02,  2.2508e-03,  1.6333e-01,\n",
       "                      -7.7485e-02,  6.7161e-02, -1.6383e-02,  7.8805e-02, -1.2106e-01,\n",
       "                       7.0012e-02, -4.5820e-02,  8.6583e-02,  1.9455e-01,  1.9135e-01,\n",
       "                       1.5811e-01,  5.5864e-03, -5.2024e-03])),\n",
       "             ('layer3.weight',\n",
       "              tensor([[ 0.0073,  0.0510, -0.0524,  ...,  0.0568,  0.0039,  0.0160],\n",
       "                      [ 0.0373, -0.0915, -0.0485,  ...,  0.0052,  0.0724,  0.0494],\n",
       "                      [-0.0295,  0.0860,  0.0143,  ...,  0.0373, -0.0387, -0.0918],\n",
       "                      ...,\n",
       "                      [-0.0056, -0.0562,  0.0015,  ..., -0.1171, -0.0478,  0.0228],\n",
       "                      [ 0.0756, -0.0614,  0.0550,  ...,  0.0091,  0.1290,  0.0364],\n",
       "                      [ 0.0232,  0.1307,  0.0666,  ...,  0.1648,  0.0671,  0.0886]])),\n",
       "             ('layer3.bias',\n",
       "              tensor([-0.0155,  0.0494,  0.1302,  0.1111,  0.0373,  0.1610,  0.0372,  0.0513,\n",
       "                      -0.0788,  0.1312,  0.0845,  0.1267,  0.0189,  0.0394, -0.0116, -0.0694,\n",
       "                       0.0783,  0.0226, -0.0580,  0.1564,  0.0287,  0.0198,  0.1696,  0.0228,\n",
       "                       0.0076,  0.1087,  0.1514,  0.1159,  0.1454, -0.0474,  0.0166,  0.0039,\n",
       "                       0.1645,  0.1766,  0.0050,  0.0226, -0.0862, -0.0060, -0.0496,  0.0563,\n",
       "                      -0.0178,  0.0936,  0.0254,  0.0082,  0.1524,  0.0674, -0.0185, -0.0418,\n",
       "                       0.2372, -0.0124, -0.0191, -0.0164,  0.0229,  0.1891, -0.0388,  0.0337,\n",
       "                       0.0481, -0.0838, -0.0702, -0.0682,  0.0742, -0.0408, -0.0542,  0.1333])),\n",
       "             ('layer4.weight',\n",
       "              tensor([[ 1.1507e-01, -3.0941e-02,  2.1681e-01, -4.3334e-01, -1.6392e-01,\n",
       "                       -1.4336e-01,  3.3457e-02, -1.1063e-01,  5.9498e-02, -3.8358e-01,\n",
       "                        5.3121e-02, -6.9195e-02,  2.6103e-01, -3.6913e-01,  4.1260e-02,\n",
       "                        1.3074e-01,  1.5722e-01, -2.2193e-01, -1.2424e-03, -2.1030e-01,\n",
       "                       -1.3952e-01,  2.5636e-01,  3.4833e-01,  8.3407e-04, -1.1776e-01,\n",
       "                        2.0168e-01, -1.6209e-01,  2.5935e-01, -1.4489e-02, -1.6064e-01,\n",
       "                        1.4377e-01,  3.1618e-01, -2.7361e-02, -5.7168e-01, -5.9745e-02,\n",
       "                        2.9109e-01, -5.6882e-02, -9.4000e-02,  3.4174e-01, -2.2907e-01,\n",
       "                       -2.1546e-01,  5.5575e-02, -1.0912e-02,  9.4461e-02, -3.4309e-01,\n",
       "                        3.9994e-03,  3.5488e-04, -5.6530e-02, -2.1891e-01, -1.2839e-02,\n",
       "                       -1.6897e-01, -1.2948e-02, -1.6065e-01, -5.2565e-01,  4.5789e-01,\n",
       "                        4.7204e-01, -3.7807e-01,  6.1884e-02,  1.7005e-01, -5.5924e-03,\n",
       "                        1.0619e-01,  3.7069e-01,  3.8788e-01, -1.9951e-01],\n",
       "                      [-2.7564e-01,  1.4947e-03, -2.1500e-02,  5.4615e-01, -9.3771e-03,\n",
       "                       -3.2637e-02, -2.1254e-02, -8.1120e-02, -1.1200e-01,  2.0012e-03,\n",
       "                        7.2983e-02,  5.2298e-01, -2.7001e-01,  1.0911e-01, -9.3353e-02,\n",
       "                        1.0073e-01, -2.4343e-01,  2.8944e-01,  1.7876e-01,  4.4186e-01,\n",
       "                        4.5281e-01, -2.6100e-03, -5.1533e-01, -1.4434e-01,  6.7247e-03,\n",
       "                       -2.6518e-02,  7.4530e-02, -1.0972e-01,  2.0910e-01,  7.9710e-02,\n",
       "                       -7.9032e-02, -2.1083e-01, -4.2840e-01,  8.7939e-02, -2.4475e-01,\n",
       "                       -3.2975e-01,  1.0657e-01, -4.2475e-02, -1.5359e-01, -1.5890e-02,\n",
       "                       -3.4332e-01, -4.3599e-01,  1.8072e-01,  3.6982e-02,  2.9373e-01,\n",
       "                       -1.0811e-01, -9.1268e-02, -4.7997e-02,  1.2476e-01,  3.0530e-02,\n",
       "                        5.2710e-02, -2.9590e-01,  1.7462e-01,  6.4488e-01, -2.2378e-01,\n",
       "                       -3.4356e-01,  1.5089e-02, -7.5654e-02, -1.2345e-01,  2.7591e-03,\n",
       "                       -2.7754e-01, -9.4493e-02,  1.0936e-01, -3.2305e-02],\n",
       "                      [ 2.7397e-01, -5.8127e-02,  3.1709e-01, -8.6044e-02, -2.2748e-02,\n",
       "                        2.6629e-02,  7.2534e-02, -3.8967e-01, -3.4833e-03,  1.5966e-01,\n",
       "                       -1.6540e-01, -9.2463e-02,  2.6418e-01, -3.4123e-01, -1.9982e-02,\n",
       "                       -5.0971e-02, -2.1292e-01,  2.5502e-01, -1.0383e-01, -2.2667e-01,\n",
       "                        2.2786e-01,  3.1834e-01, -3.6446e-01, -5.5779e-02,  3.3748e-02,\n",
       "                       -1.7642e-01, -4.1163e-01,  2.4728e-01,  4.5068e-01,  1.3256e-01,\n",
       "                       -7.9260e-02,  4.3626e-02,  1.3703e-01, -3.6277e-01,  3.3625e-01,\n",
       "                       -1.5763e-01, -9.7655e-02, -6.2735e-02,  2.4929e-01, -2.2039e-01,\n",
       "                        2.8554e-01, -1.1658e-01, -2.9920e-01,  4.7146e-02,  8.2963e-02,\n",
       "                       -7.7672e-02, -5.5628e-02, -1.4833e-02,  4.1871e-02, -1.5856e-01,\n",
       "                        4.8805e-01,  6.4429e-02, -3.1543e-02,  3.5321e-01, -1.5007e-01,\n",
       "                        5.2167e-02,  7.5538e-02, -7.0398e-02,  2.3024e-01,  9.9592e-02,\n",
       "                        2.1176e-01,  5.5816e-02, -9.5233e-02, -3.2670e-01],\n",
       "                      [ 1.7077e-01, -6.1573e-02,  9.5297e-02,  1.2029e-01, -2.4675e-01,\n",
       "                       -4.8159e-02,  1.9300e-01,  1.9110e-01,  1.1127e-02, -2.8902e-01,\n",
       "                       -5.5217e-02, -4.1269e-01, -1.9217e-02,  6.7157e-01,  8.5330e-04,\n",
       "                       -4.2902e-02,  1.6545e-01, -7.4569e-03,  1.9117e-01, -3.4940e-01,\n",
       "                       -4.5449e-01, -2.4974e-01, -8.9908e-02,  4.9510e-01, -1.6611e-02,\n",
       "                       -8.1674e-02,  3.1811e-01, -4.7534e-02, -1.1654e-01, -4.7059e-02,\n",
       "                        1.5723e-03,  4.8753e-02, -3.4672e-01,  1.5263e-02,  3.2673e-01,\n",
       "                        1.2169e-01, -1.0653e-01,  4.4213e-02, -2.4894e-01, -1.6656e-01,\n",
       "                        1.3993e-01, -2.8080e-01,  6.2507e-02, -2.6582e-01,  1.0895e-01,\n",
       "                       -1.8091e-01, -5.6234e-02, -1.1662e-01, -2.1378e-01, -1.7950e-01,\n",
       "                        2.8389e-01, -1.9899e-01,  1.9639e-01,  2.2806e-01,  1.9457e-01,\n",
       "                       -1.7618e-01,  4.5285e-01,  1.5357e-03, -1.6711e-01, -1.1249e-01,\n",
       "                       -2.4737e-01, -8.1786e-02, -3.5384e-01,  2.6779e-01],\n",
       "                      [-1.2955e-01,  2.7219e-01,  5.0242e-02,  2.1434e-02,  1.3534e-01,\n",
       "                        1.7923e-01, -1.8574e-01, -2.5244e-01, -8.1295e-02,  6.1349e-01,\n",
       "                        2.8764e-01,  1.2417e-02, -4.6610e-01, -1.8443e-01,  1.2269e-01,\n",
       "                       -2.0375e-02,  1.8246e-01, -5.0378e-02, -1.1480e-01,  2.7053e-01,\n",
       "                        1.5887e-01, -2.3638e-01, -2.9873e-01, -2.2359e-01, -5.6750e-02,\n",
       "                        3.7396e-01, -1.9980e-01,  2.3558e-02, -1.6668e-01, -4.7999e-02,\n",
       "                        1.2096e-01, -4.1882e-01,  5.6107e-01,  3.0510e-01, -3.8068e-01,\n",
       "                        1.9485e-01,  1.2036e-01,  5.0262e-02, -1.5175e-01,  2.6610e-01,\n",
       "                        1.0468e-01,  4.2252e-01, -1.0276e-01, -2.6570e-01, -3.3244e-01,\n",
       "                        3.8772e-02,  5.1954e-02, -4.3390e-02,  4.9264e-01,  2.7681e-01,\n",
       "                       -1.0634e-01,  6.3507e-02, -4.1070e-01,  7.5784e-02, -3.1753e-01,\n",
       "                       -1.7384e-01,  1.4356e-01,  1.0562e-02, -1.9642e-01, -1.3128e-01,\n",
       "                       -2.4018e-01, -1.8587e-01,  5.3046e-02, -1.5809e-01],\n",
       "                      [ 7.2572e-03,  1.2966e-01,  3.8685e-01, -1.7573e-01, -6.1418e-02,\n",
       "                        8.4403e-05,  1.6650e-01,  8.3080e-02,  1.2575e-01, -2.3532e-02,\n",
       "                       -3.0172e-02, -4.6195e-02, -1.7641e-01,  2.0498e-01,  1.0699e-01,\n",
       "                       -7.4246e-02, -1.1355e-01,  1.1832e-02, -2.0894e-01,  8.1625e-02,\n",
       "                       -9.3785e-02, -3.6495e-01,  1.1608e+00, -8.7047e-02, -3.7837e-02,\n",
       "                        6.0107e-04,  5.4161e-01,  2.1379e-02, -6.0502e-02, -4.1010e-02,\n",
       "                        1.1512e-02, -1.6265e-01,  8.7440e-03,  2.6245e-01,  5.3553e-03,\n",
       "                       -1.5950e-01,  7.0067e-02,  3.5355e-02, -2.6702e-01, -5.1523e-01,\n",
       "                       -4.6127e-01,  1.7938e-01,  5.0106e-01,  1.1820e-01,  1.1820e-01,\n",
       "                        1.8896e-01,  5.9084e-03,  1.1242e-01, -3.6453e-01, -8.5384e-02,\n",
       "                       -2.1700e-01, -1.1508e-01,  3.7660e-01, -8.8809e-02,  1.1879e-01,\n",
       "                       -3.3283e-01, -1.6853e-01,  4.1575e-02, -3.9318e-01,  5.0206e-02,\n",
       "                       -1.5990e-01, -6.4640e-03, -1.8577e-01, -1.4052e-01],\n",
       "                      [-3.3609e-01,  3.1877e-02, -2.2915e-01, -2.4608e-02,  3.8040e-01,\n",
       "                       -2.1564e-02, -6.8341e-02,  4.9494e-01,  1.6610e-02,  3.9263e-01,\n",
       "                       -1.7590e-01, -1.8612e-01, -2.8261e-01, -3.6877e-01,  1.0761e-01,\n",
       "                       -1.0648e-01, -3.9727e-01,  2.4814e-01, -1.3453e-01,  2.4098e-01,\n",
       "                        1.8765e-02, -4.1405e-02,  2.1928e-01, -3.9436e-01,  6.1444e-02,\n",
       "                        2.4031e-01, -2.7306e-01,  3.1762e-01,  4.4464e-01, -7.3960e-03,\n",
       "                       -1.3694e-01, -3.7332e-02,  3.7332e-01, -3.0472e-01, -2.9363e-01,\n",
       "                        1.7244e-02, -5.5126e-03, -1.0088e-01,  3.0015e-01, -5.6954e-03,\n",
       "                       -3.4664e-01, -3.4164e-01,  2.1970e-01,  3.1235e-01, -2.4869e-01,\n",
       "                       -2.4765e-01, -7.7286e-02,  6.6429e-02, -2.0943e-01,  1.2526e-01,\n",
       "                       -1.9103e-01,  3.1399e-01,  8.8537e-02, -4.3423e-01,  3.5478e-01,\n",
       "                       -1.9480e-01, -1.5246e-01,  4.7001e-02,  2.2434e-01,  9.0841e-02,\n",
       "                       -9.7967e-02,  3.6313e-02, -1.1315e-01, -3.3782e-01],\n",
       "                      [ 5.3926e-04, -8.8702e-02, -2.7545e-01, -4.4241e-02, -6.4036e-02,\n",
       "                        5.5049e-01,  1.1461e-01, -8.7132e-03,  1.2201e-01, -5.3009e-01,\n",
       "                       -2.7586e-01,  1.6813e-01,  2.1277e-01, -1.3750e-01, -1.0799e-01,\n",
       "                       -2.5959e-02, -4.5605e-01,  3.3739e-02, -1.0553e-01,  2.0623e-01,\n",
       "                        1.0324e-01,  1.2777e-01, -5.6960e-01, -1.9880e-01, -6.1670e-02,\n",
       "                        1.2554e-01, -2.2306e-01,  2.5853e-02, -1.2702e-01,  2.2594e-01,\n",
       "                        4.4782e-02,  3.6056e-01, -3.5596e-01,  2.9110e-01, -1.8615e-01,\n",
       "                       -1.4251e-01,  7.9348e-02, -7.5732e-02, -7.6805e-02, -2.2683e-01,\n",
       "                        3.4731e-01,  2.1530e-01, -3.4529e-02, -2.2210e-02,  4.7613e-01,\n",
       "                        2.9519e-01,  2.4295e-02, -3.8334e-02,  4.7654e-01, -2.2807e-01,\n",
       "                        3.2089e-01, -3.7396e-01, -3.7626e-01,  1.8982e-01, -2.0423e-01,\n",
       "                        2.8732e-01, -3.1817e-01, -4.6262e-02, -8.0767e-03, -3.2947e-02,\n",
       "                        6.9245e-03,  3.5743e-01, -6.6829e-02,  4.9095e-01],\n",
       "                      [-2.0638e-01, -2.7655e-02, -2.3864e-01,  2.0493e-01,  2.9545e-01,\n",
       "                       -4.2490e-01, -5.3018e-02,  4.5191e-02, -6.2172e-02,  6.2445e-03,\n",
       "                        1.2843e-01, -4.1024e-01,  6.6205e-02,  6.4831e-02,  2.1148e-02,\n",
       "                       -3.6494e-02,  5.3001e-01,  1.9367e-01,  3.5357e-01, -3.7317e-01,\n",
       "                        3.6395e-01,  3.4125e-01,  2.4862e-01, -4.6243e-02,  7.2948e-02,\n",
       "                       -2.2919e-01,  1.7745e-01, -4.4338e-01, -3.5226e-01, -1.6763e-01,\n",
       "                       -1.7712e-02,  2.1045e-01,  3.1457e-02,  1.1987e-01, -2.3296e-02,\n",
       "                        7.3525e-02,  3.1632e-02, -2.7907e-02, -1.1554e-01,  4.5367e-01,\n",
       "                        2.8928e-02,  8.9641e-02, -3.6316e-01, -8.6951e-02, -2.5380e-01,\n",
       "                       -2.7395e-01, -3.2548e-02, -9.8710e-02, -5.3078e-01, -1.6884e-01,\n",
       "                       -3.7880e-03,  3.6899e-01,  5.4216e-01, -3.1566e-02, -3.7946e-01,\n",
       "                       -2.2174e-02,  2.8179e-01,  2.1331e-02,  1.3783e-01, -7.1328e-02,\n",
       "                        2.2719e-01,  1.2047e-01, -1.6674e-01, -2.6824e-01],\n",
       "                      [ 3.3077e-02, -1.8547e-02, -2.6623e-01, -3.2928e-01, -1.0578e-01,\n",
       "                       -1.1464e-01, -7.2337e-03, -6.2699e-03,  1.2989e-02, -2.0667e-02,\n",
       "                        3.7528e-01,  2.5869e-01,  2.6728e-01, -3.2050e-02,  8.6618e-02,\n",
       "                        6.6523e-02,  2.4152e-01, -2.2996e-01,  1.4667e-01, -1.5850e-01,\n",
       "                       -3.7669e-01, -1.3292e-01,  2.0242e-02,  1.9857e-01,  9.2602e-02,\n",
       "                       -5.0964e-01,  4.5275e-01,  1.1328e-01, -3.5546e-01, -2.3301e-01,\n",
       "                       -1.5788e-01, -2.8404e-01,  1.7266e-01,  5.2581e-01,  2.7172e-01,\n",
       "                        2.1938e-01,  4.0690e-02,  8.1221e-02,  5.3629e-02,  4.5510e-01,\n",
       "                        3.4609e-02,  1.2472e-01,  1.1017e-01, -1.7671e-01, -1.5822e-01,\n",
       "                        6.9920e-02,  5.6993e-02,  5.9815e-02,  4.5219e-01,  6.1807e-02,\n",
       "                       -4.1738e-01, -3.2895e-01,  6.4125e-02, -3.8972e-01, -1.0251e-01,\n",
       "                        2.7852e-01, -1.5954e-01, -1.6319e-02, -1.0017e-01,  2.3361e-02,\n",
       "                        2.3639e-01, -4.0582e-01,  1.6187e-01,  5.2703e-01]])),\n",
       "             ('layer4.bias',\n",
       "              tensor([-0.1348,  0.1377,  0.0795, -0.0409, -0.0084,  0.2218, -0.0650, -0.0622,\n",
       "                      -0.2315,  0.0022]))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('layer1.weight', tensor([[ 0.0300,  0.0186, -0.0152,  ...,  0.0091,  0.0066,  0.0074],\n",
      "        [-0.0316,  0.0183, -0.0271,  ...,  0.0016, -0.0105,  0.0278],\n",
      "        [ 0.0037, -0.0225, -0.0094,  ...,  0.0177, -0.0025, -0.0206],\n",
      "        ...,\n",
      "        [ 0.0308,  0.0230, -0.0005,  ...,  0.0159, -0.0093, -0.0080],\n",
      "        [-0.0084, -0.0063,  0.0293,  ...,  0.0324,  0.0310, -0.0263],\n",
      "        [-0.0104,  0.0108, -0.0006,  ...,  0.0222, -0.0183,  0.0276]])), ('layer1.bias', tensor([ 0.0231,  0.0273,  0.0290, -0.0112, -0.0063, -0.0245,  0.0209,  0.0344,\n",
      "        -0.0116, -0.0310,  0.0042,  0.0247,  0.0297,  0.0280, -0.0317,  0.0203,\n",
      "        -0.0333, -0.0201,  0.0076,  0.0217,  0.0254,  0.0329,  0.0148, -0.0261,\n",
      "         0.0062,  0.0041,  0.0228,  0.0030, -0.0064,  0.0269,  0.0111,  0.0075,\n",
      "         0.0102,  0.0001, -0.0099,  0.0116,  0.0268,  0.0180,  0.0118, -0.0157,\n",
      "        -0.0095, -0.0222,  0.0107, -0.0177,  0.0244, -0.0176, -0.0264, -0.0291,\n",
      "         0.0175, -0.0079, -0.0017,  0.0187, -0.0298,  0.0254, -0.0024, -0.0313,\n",
      "         0.0308, -0.0234, -0.0144, -0.0291, -0.0104,  0.0314,  0.0266, -0.0262])), ('layer2.weight', tensor([[-0.0679, -0.0367, -0.1122,  ..., -0.0414, -0.0698,  0.0731],\n",
      "        [-0.0201, -0.0423, -0.1139,  ..., -0.0999,  0.0002, -0.0696],\n",
      "        [ 0.0790,  0.1080, -0.0395,  ..., -0.0580,  0.0866,  0.1167],\n",
      "        ...,\n",
      "        [ 0.0435,  0.0643,  0.1200,  ..., -0.0683,  0.0917, -0.0201],\n",
      "        [ 0.1231,  0.0445,  0.0130,  ..., -0.0541,  0.0689, -0.0818],\n",
      "        [ 0.1083, -0.0046,  0.0585,  ..., -0.0090,  0.0335, -0.0127]])), ('layer2.bias', tensor([-0.0303,  0.0005, -0.0453, -0.0999, -0.0735,  0.0653,  0.0385,  0.1229,\n",
      "        -0.0989,  0.1230, -0.0243,  0.0293, -0.0183,  0.0362,  0.1246,  0.0602,\n",
      "         0.0639, -0.0663,  0.1200, -0.0709,  0.0556, -0.0414,  0.1196,  0.1066,\n",
      "         0.0534, -0.0855, -0.0109, -0.0357, -0.0052, -0.0896,  0.1105,  0.1095,\n",
      "         0.1230, -0.0564,  0.0135,  0.0179, -0.0322, -0.0938,  0.0868, -0.0996,\n",
      "         0.0166, -0.0258,  0.0728, -0.1141,  0.1164,  0.1093, -0.0127,  0.1017,\n",
      "         0.0192, -0.1090,  0.0134, -0.0188, -0.0011, -0.0764,  0.0330, -0.0537,\n",
      "        -0.0428, -0.1243, -0.1215, -0.0580,  0.1236,  0.0014,  0.0469,  0.0993,\n",
      "         0.0794,  0.0007, -0.0287, -0.0623, -0.0373,  0.0502,  0.0720,  0.0481,\n",
      "         0.0256, -0.0279,  0.0241,  0.0867, -0.1158, -0.0166,  0.1138,  0.0295,\n",
      "        -0.0752,  0.0722,  0.0628,  0.0309, -0.0997, -0.0408,  0.0366, -0.0729,\n",
      "         0.0409, -0.0488,  0.1104,  0.0120, -0.0629, -0.1148,  0.0250,  0.0192,\n",
      "         0.1166, -0.0355, -0.0490, -0.0437,  0.0638,  0.1214,  0.0179,  0.1079,\n",
      "        -0.0441, -0.0626, -0.0256, -0.1186,  0.0707, -0.1181, -0.0990, -0.1135,\n",
      "        -0.1239,  0.0767,  0.0527,  0.0088, -0.0992,  0.0437, -0.0877, -0.0867,\n",
      "         0.0256, -0.0519, -0.0894,  0.1123,  0.0014,  0.0362, -0.0892, -0.1188])), ('layer3.weight', tensor([[ 0.0005,  0.0489, -0.0548,  ...,  0.0242,  0.0115,  0.0294],\n",
      "        [ 0.0085,  0.0471,  0.0014,  ...,  0.0442, -0.0322, -0.0007],\n",
      "        [ 0.0427, -0.0882,  0.0009,  ...,  0.0084, -0.0646, -0.0303],\n",
      "        ...,\n",
      "        [ 0.0362,  0.0433, -0.0018,  ..., -0.0206, -0.0252, -0.0094],\n",
      "        [ 0.0543,  0.0794,  0.0142,  ..., -0.0027, -0.0341, -0.0014],\n",
      "        [-0.0818,  0.0850,  0.0483,  ..., -0.0876,  0.0538,  0.0066]])), ('layer3.bias', tensor([ 7.5347e-02,  6.0757e-03, -8.5603e-03, -2.6532e-02,  7.4842e-02,\n",
      "         2.6176e-02,  3.0961e-02, -1.1848e-02, -2.4045e-05,  9.2955e-03,\n",
      "         5.1978e-02, -1.5574e-02, -4.4282e-02, -4.8558e-02, -3.4725e-02,\n",
      "        -3.5594e-02,  4.5674e-02,  1.0163e-02,  2.5511e-02,  3.3505e-02,\n",
      "         7.2860e-02, -1.7535e-02, -7.3429e-02, -1.4158e-02, -3.0085e-02,\n",
      "        -3.5080e-02, -4.8006e-02, -4.7846e-02,  6.4829e-02, -5.2108e-02,\n",
      "        -5.1854e-03,  1.9974e-02, -7.5653e-02, -6.8663e-02,  3.1137e-02,\n",
      "         2.9503e-02, -4.0173e-02,  1.5631e-02,  9.2923e-03,  8.0373e-02,\n",
      "        -8.6862e-03, -5.8749e-02, -1.0896e-02, -7.3838e-02, -5.6531e-02,\n",
      "         4.3029e-02, -6.2298e-02,  1.1833e-02, -7.0263e-02,  1.9348e-02,\n",
      "        -4.6153e-02,  2.1992e-02, -4.1505e-02, -1.2925e-02, -6.4558e-02,\n",
      "        -4.0375e-03,  5.7492e-02, -1.9781e-02, -5.6883e-02, -3.7503e-02,\n",
      "        -8.4523e-02, -1.8781e-02,  2.7906e-02, -5.4611e-02])), ('layer4.weight', tensor([[-1.0138e-01,  1.7885e-02, -4.6950e-02,  1.0055e-02,  1.0779e-02,\n",
      "          1.1363e-02, -9.7996e-02, -5.8344e-02, -3.8871e-02, -9.9689e-06,\n",
      "         -5.4602e-02,  8.0469e-02,  1.5465e-02,  7.6936e-02, -2.7402e-02,\n",
      "         -8.7094e-02,  4.8918e-02,  1.1284e-01, -5.3002e-02, -1.0229e-01,\n",
      "         -7.2276e-02, -8.6375e-02,  1.5149e-02, -2.5492e-02, -1.0984e-01,\n",
      "          4.7438e-02,  1.2849e-02, -9.0812e-02,  9.9307e-02,  4.0135e-02,\n",
      "          1.1028e-01, -1.7568e-02, -6.4528e-02, -9.0510e-02, -2.8608e-02,\n",
      "         -5.7972e-03,  1.1088e-01,  1.1972e-01, -2.0164e-02,  1.0267e-01,\n",
      "         -1.0559e-02, -3.5364e-02, -7.1544e-02, -7.4443e-02, -1.0394e-01,\n",
      "         -1.9492e-02,  6.7540e-02, -4.9095e-02,  5.7318e-02,  9.0630e-02,\n",
      "          5.7657e-02, -1.1772e-01,  4.1676e-02, -9.4155e-02,  2.2794e-03,\n",
      "         -1.6019e-02, -4.9389e-02,  1.0966e-01, -2.8640e-02,  8.1519e-02,\n",
      "          7.5675e-02, -8.0222e-02,  6.9223e-02, -1.2487e-01],\n",
      "        [-6.9359e-02,  1.1599e-01,  3.7016e-02, -2.9388e-02,  1.0117e-01,\n",
      "         -1.1620e-01, -1.5465e-02,  1.2269e-01, -4.2365e-03,  1.2400e-01,\n",
      "         -8.7381e-02, -9.9465e-02,  1.1270e-01,  2.4269e-02, -8.8549e-02,\n",
      "         -7.2078e-03, -8.5645e-02, -6.8396e-02, -2.7359e-02, -1.2120e-01,\n",
      "          2.9429e-02,  9.0255e-02, -4.9216e-02,  8.5366e-02, -6.0183e-02,\n",
      "         -8.5092e-03, -3.9969e-02, -3.9044e-02, -7.9467e-02,  6.0376e-02,\n",
      "         -3.1684e-02, -7.6722e-02,  3.0992e-02, -4.2264e-02,  9.4717e-02,\n",
      "          5.7241e-02, -7.1976e-02, -6.0437e-02,  8.2773e-02,  3.1557e-02,\n",
      "          1.0701e-01, -7.4913e-02, -1.0921e-01, -8.2051e-02,  6.2962e-02,\n",
      "          9.5646e-02,  4.4590e-02,  6.3821e-02,  6.5719e-02,  1.1745e-01,\n",
      "          2.6657e-02,  2.1040e-02, -9.0928e-02, -9.1195e-02, -1.0714e-01,\n",
      "         -3.3446e-02, -1.8929e-02, -1.1900e-02, -1.2466e-01, -1.2288e-01,\n",
      "          6.2503e-02, -4.9862e-02, -5.3927e-02,  9.6376e-02],\n",
      "        [ 9.6438e-02, -7.5494e-02, -1.2434e-01, -9.0948e-02,  2.6745e-02,\n",
      "         -2.6372e-02, -1.2083e-01, -6.5674e-02, -9.2124e-03, -1.2272e-01,\n",
      "         -2.9212e-02,  9.8969e-02, -1.2197e-01, -8.9898e-02,  8.2447e-02,\n",
      "         -1.0556e-01,  1.2108e-01, -7.2205e-02, -8.6395e-02,  3.7623e-02,\n",
      "         -6.8936e-02, -6.5967e-02,  3.4266e-03,  1.0972e-01,  1.4652e-02,\n",
      "         -7.5167e-02,  5.1431e-02, -1.0129e-01,  3.7909e-02,  1.4072e-02,\n",
      "         -4.3038e-02, -1.0831e-01,  1.0393e-01,  1.6125e-02,  1.7407e-02,\n",
      "          4.4920e-02,  5.0512e-02,  9.2647e-02, -2.6621e-02, -6.0449e-02,\n",
      "         -2.2995e-02, -3.8141e-02, -5.0194e-02, -6.2284e-02, -8.1357e-02,\n",
      "         -7.9829e-02,  4.2555e-02,  8.2620e-02, -2.1974e-02,  2.4639e-03,\n",
      "          6.1314e-02, -4.6460e-02, -7.1725e-02, -7.1468e-02, -4.1781e-02,\n",
      "          1.0746e-01,  9.6887e-02, -7.3392e-02,  5.7712e-02,  1.0899e-01,\n",
      "          3.4397e-02,  8.7474e-02, -6.4049e-02, -1.1417e-01],\n",
      "        [-9.6052e-02,  1.2025e-01,  2.3191e-02, -1.9717e-02, -1.9392e-02,\n",
      "         -7.4399e-03, -8.8819e-02,  1.1278e-02, -1.2205e-01,  2.9669e-03,\n",
      "         -1.0235e-01,  9.9821e-02,  4.7511e-02,  1.5294e-02,  1.0691e-01,\n",
      "         -1.0530e-01,  2.8956e-02, -1.1525e-01,  1.2333e-01,  1.1728e-01,\n",
      "         -2.0232e-02,  5.8777e-02,  7.9034e-02, -1.1465e-01, -1.1620e-01,\n",
      "         -1.0316e-01, -3.3016e-02, -1.9950e-02, -7.3811e-02, -1.1554e-01,\n",
      "          1.0991e-01, -9.1411e-02,  9.6611e-02,  9.5047e-02, -9.2715e-02,\n",
      "         -1.1213e-01,  1.0514e-01, -9.8052e-02, -4.3107e-02,  3.8327e-02,\n",
      "         -9.9468e-02,  7.6080e-02,  9.6902e-02, -6.4143e-02,  3.5673e-02,\n",
      "         -3.5829e-02, -1.2126e-01, -5.0043e-02,  1.1333e-01,  6.9334e-03,\n",
      "          5.1603e-02, -3.6838e-02,  6.5272e-02,  6.2282e-02, -2.0115e-02,\n",
      "         -6.1420e-02,  1.0311e-01, -1.0209e-01, -3.6089e-02, -1.2445e-01,\n",
      "         -6.3109e-03,  9.2625e-02,  1.0331e-01, -6.4569e-02],\n",
      "        [-2.5185e-02, -6.3617e-02, -2.0680e-02,  6.7498e-02,  1.1971e-01,\n",
      "          1.0470e-01, -1.2454e-01,  1.1625e-01,  7.3058e-02, -4.7085e-02,\n",
      "          8.1923e-02, -1.6182e-02,  6.3778e-02, -3.6174e-02,  1.0748e-01,\n",
      "         -2.6060e-02,  4.5066e-02, -8.8018e-02, -5.6032e-02, -5.7982e-03,\n",
      "         -6.3817e-02,  1.8466e-02, -1.2361e-01,  2.0127e-02,  7.7893e-02,\n",
      "          1.1848e-01, -5.3825e-02,  1.1485e-01, -7.5110e-02,  2.5139e-02,\n",
      "          5.5545e-02, -1.1270e-01, -8.6007e-02, -7.2445e-02,  6.1937e-02,\n",
      "         -1.1338e-01,  9.2563e-02, -9.1365e-02,  7.6539e-02, -6.9556e-02,\n",
      "          6.6083e-02, -1.0405e-01, -5.1554e-03,  3.0336e-02,  5.5700e-02,\n",
      "          1.7407e-02,  6.2092e-03,  1.2048e-02,  4.1463e-02,  6.4135e-02,\n",
      "          5.2288e-02, -5.8595e-02,  2.1016e-02,  7.6941e-02, -2.4862e-02,\n",
      "         -1.8155e-02, -2.8655e-02,  5.8912e-02, -3.2313e-02,  3.0633e-02,\n",
      "         -5.2521e-03,  8.6750e-02, -2.6183e-02,  9.7890e-02],\n",
      "        [-3.5540e-02, -9.2336e-02,  6.3853e-02,  5.5951e-02,  2.7874e-03,\n",
      "          2.7103e-02, -1.9383e-02, -5.6365e-02, -1.9476e-02,  7.7216e-02,\n",
      "          7.4615e-02,  8.0739e-02,  4.3713e-02, -1.2114e-01,  8.5520e-03,\n",
      "         -7.1049e-02,  3.0993e-02,  8.3928e-02, -1.0512e-01, -1.2421e-01,\n",
      "         -1.0151e-01, -3.7565e-02, -2.0549e-02,  5.3849e-02,  7.9367e-02,\n",
      "         -8.7426e-02, -2.5826e-02, -1.0081e-01, -1.0107e-01, -1.1151e-01,\n",
      "          1.0078e-01,  1.0005e-01,  3.8212e-02, -2.4754e-02,  8.0240e-02,\n",
      "         -4.4365e-03, -2.9585e-02, -1.2057e-01, -6.0035e-02, -1.1749e-02,\n",
      "          9.7817e-02,  4.1750e-02, -8.0008e-02,  4.2049e-02, -3.5911e-02,\n",
      "         -1.2046e-01,  8.8425e-02, -3.4811e-02, -8.4877e-02,  8.0517e-02,\n",
      "         -1.3504e-02, -3.0394e-02, -8.9813e-02, -7.9368e-02,  1.1567e-01,\n",
      "          1.7866e-03,  6.4701e-02, -9.3964e-02, -7.2302e-02,  9.9235e-02,\n",
      "          7.4206e-02, -1.0203e-01,  5.8922e-03, -1.1258e-01],\n",
      "        [-5.2834e-02, -8.3426e-02,  6.2853e-02, -8.6168e-02, -4.2998e-02,\n",
      "         -4.4514e-02,  6.8990e-02,  9.3693e-02, -7.2180e-02,  7.6726e-02,\n",
      "         -1.8448e-02, -9.2941e-02,  1.1673e-01, -2.5590e-02,  9.9852e-02,\n",
      "          1.1846e-01,  5.6999e-02,  9.9193e-02, -5.1277e-03, -1.5464e-02,\n",
      "          3.2905e-02, -6.2424e-02, -9.2287e-02, -1.0410e-01, -4.0456e-02,\n",
      "          1.1661e-01,  9.5335e-02,  5.7521e-02, -8.4354e-02,  1.1664e-01,\n",
      "          9.6329e-02, -1.1311e-01, -4.0933e-02, -9.3341e-02, -1.9157e-02,\n",
      "         -9.0889e-02, -7.1933e-02,  1.0910e-01, -8.3384e-02, -7.1422e-02,\n",
      "          5.4341e-02,  1.9323e-02, -4.3981e-02, -1.2486e-01, -1.0762e-02,\n",
      "          7.7105e-02,  7.5277e-02, -8.0056e-02,  2.5988e-02, -8.8443e-02,\n",
      "          6.0280e-02, -5.7284e-02, -1.5363e-02,  1.0784e-01, -7.0033e-02,\n",
      "         -4.5641e-02, -3.4780e-03, -1.0619e-01,  7.5548e-02, -6.4977e-02,\n",
      "          5.3938e-02, -1.2230e-01,  3.1495e-02, -9.6574e-02],\n",
      "        [-5.1905e-02,  1.0183e-01, -1.0672e-01,  4.8361e-03, -7.4062e-02,\n",
      "         -6.6418e-02,  1.1228e-01,  8.7363e-02, -3.5154e-02,  7.1571e-02,\n",
      "         -3.3998e-02,  1.0358e-01, -2.1642e-02,  2.9160e-04, -3.3553e-02,\n",
      "         -4.4465e-02, -1.1326e-01,  9.3061e-02,  1.1449e-01, -1.1802e-01,\n",
      "         -4.2921e-02, -1.1243e-01, -7.1492e-02, -1.1105e-01, -7.3162e-03,\n",
      "         -8.0738e-02,  9.6869e-02, -6.1524e-02, -1.0222e-01,  1.1531e-01,\n",
      "         -9.9248e-02,  2.4157e-02, -3.0633e-03,  1.9335e-02,  4.0920e-02,\n",
      "         -3.5397e-02, -5.5079e-04,  9.6289e-02,  8.5994e-02, -1.8654e-02,\n",
      "          7.0548e-02, -6.3028e-02,  2.7638e-02,  6.7452e-02, -1.1730e-01,\n",
      "         -6.7069e-02, -9.0515e-02, -5.1072e-02, -8.5992e-02,  6.4198e-03,\n",
      "          1.2204e-01,  1.1545e-01, -4.8291e-03,  6.8059e-02, -9.3845e-02,\n",
      "          7.9510e-02, -1.1850e-01, -9.5812e-02, -9.7981e-02, -6.5594e-02,\n",
      "         -1.2271e-01, -8.2967e-02,  7.6435e-03,  1.1646e-01],\n",
      "        [-1.2162e-01, -7.5675e-03, -4.3051e-02, -3.3285e-02, -9.7821e-02,\n",
      "          7.3027e-02, -2.1929e-03, -4.7924e-02, -3.3387e-02, -6.1690e-02,\n",
      "         -2.1606e-02,  6.8091e-02,  2.3624e-02, -4.3649e-02, -4.0736e-02,\n",
      "          9.9005e-02, -2.7018e-02, -5.4950e-02, -9.8366e-02, -4.6427e-02,\n",
      "          7.9842e-02, -3.6293e-02, -8.5797e-02, -5.3091e-02, -4.6847e-02,\n",
      "         -4.3828e-02, -2.7437e-02,  5.9484e-03, -9.2272e-02,  6.8006e-02,\n",
      "         -7.2226e-02, -8.8590e-02, -3.4996e-02,  2.2287e-02, -9.8159e-02,\n",
      "          3.1321e-02,  9.7415e-02, -9.6480e-02, -2.7356e-02,  6.8151e-02,\n",
      "         -1.1454e-01,  8.9773e-02, -6.1868e-02, -4.2714e-02,  9.4136e-02,\n",
      "         -1.4007e-02,  9.7471e-02,  5.8425e-02,  3.7114e-02,  9.0805e-02,\n",
      "         -2.9982e-02,  7.1290e-04,  4.2524e-02, -1.1976e-01, -1.0519e-01,\n",
      "          1.7970e-02, -8.2892e-02,  4.3601e-02,  6.5179e-02, -1.0121e-01,\n",
      "          1.5729e-02, -8.1671e-02, -9.1975e-02,  1.0471e-01],\n",
      "        [-2.4419e-02,  5.0045e-02,  5.1464e-02,  4.9077e-02, -4.2798e-02,\n",
      "          3.0731e-02, -1.2131e-01,  1.0044e-01,  3.9119e-02,  1.2171e-01,\n",
      "          5.1590e-02,  1.0799e-01, -8.7077e-02,  2.1443e-02, -1.2421e-01,\n",
      "          1.0456e-01,  7.7850e-02,  1.1260e-01, -1.0078e-01, -2.3559e-02,\n",
      "          5.5880e-02,  1.0701e-01,  8.6167e-02, -3.9880e-02,  2.9137e-02,\n",
      "         -9.3285e-02, -6.0181e-02,  9.8269e-02, -8.1030e-02,  6.2930e-02,\n",
      "          8.5398e-02, -2.7795e-02, -1.0102e-01, -9.5773e-03,  6.9244e-02,\n",
      "         -5.8499e-02, -1.0508e-01, -1.1815e-01,  1.1425e-01, -8.6295e-02,\n",
      "          1.0160e-01, -6.0393e-02,  8.6083e-03,  3.9056e-02, -8.7003e-02,\n",
      "         -1.0392e-01,  4.1222e-02,  5.7940e-04,  3.2519e-02,  7.7352e-02,\n",
      "         -4.2023e-02,  6.5579e-02, -7.2644e-02, -9.2411e-02,  4.3190e-02,\n",
      "         -7.5955e-02, -3.3867e-02,  4.6915e-02, -3.3812e-02,  7.0285e-02,\n",
      "          4.7260e-02, -3.1482e-02, -8.8445e-02,  2.2715e-02]])), ('layer4.bias', tensor([ 0.0239, -0.0846,  0.0792, -0.0984, -0.0906, -0.0633,  0.0695,  0.0313,\n",
      "        -0.0884,  0.0777]))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.3049659729003906, 'val_acc': 0.10214843600988388}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = MnistModel(784,10)\n",
    "print(model2.state_dict())\n",
    "evaluate(model2, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer1.weight',\n",
       "              tensor([[-2.3459e-02, -2.5167e-02, -1.3336e-02,  ...,  9.3090e-03,\n",
       "                       -8.1156e-03, -3.1615e-02],\n",
       "                      [ 2.5964e-02,  1.8885e-02, -1.0100e-02,  ..., -2.6874e-02,\n",
       "                       -1.9925e-03, -2.9954e-02],\n",
       "                      [ 1.6361e-02,  3.3987e-02,  2.3278e-02,  ..., -3.7107e-03,\n",
       "                       -1.3555e-02,  2.9773e-02],\n",
       "                      ...,\n",
       "                      [-1.7228e-03, -3.4604e-02, -2.2041e-02,  ..., -3.1494e-02,\n",
       "                       -7.4112e-03,  1.4982e-02],\n",
       "                      [ 9.8619e-03,  2.1688e-02, -1.4468e-02,  ..., -3.1331e-02,\n",
       "                        2.0164e-02, -2.7014e-02],\n",
       "                      [ 2.0179e-02,  8.3857e-03,  3.0747e-02,  ..., -2.3913e-02,\n",
       "                        1.9141e-02,  6.7008e-05]])),\n",
       "             ('layer1.bias',\n",
       "              tensor([ 0.0790,  0.1563,  0.0182,  0.0471,  0.0198,  0.0262,  0.0133, -0.0519,\n",
       "                       0.0567, -0.1144,  0.0997,  0.0380,  0.0350,  0.1254,  0.0395,  0.0560,\n",
       "                      -0.1135,  0.0580,  0.0574, -0.0053, -0.0598, -0.0211,  0.0010,  0.1234,\n",
       "                       0.0870,  0.0373, -0.0268,  0.1492,  0.0037, -0.0125, -0.0860, -0.0113,\n",
       "                       0.0726, -0.0677,  0.1116,  0.1071,  0.1234,  0.0885,  0.0342, -0.0230,\n",
       "                       0.0653,  0.0352,  0.0790, -0.0215,  0.0351, -0.0636, -0.0395,  0.0199,\n",
       "                       0.0391,  0.0373, -0.0850,  0.0151, -0.0320,  0.0026,  0.0461,  0.0289,\n",
       "                       0.0128,  0.0341, -0.0201,  0.0372,  0.1353, -0.0057,  0.1090,  0.0227])),\n",
       "             ('layer2.weight',\n",
       "              tensor([[-0.0482, -0.0803,  0.0721,  ...,  0.0541,  0.0147, -0.1178],\n",
       "                      [ 0.1596,  0.0716, -0.1173,  ...,  0.0013, -0.2655,  0.0814],\n",
       "                      [-0.0952,  0.1057,  0.0596,  ...,  0.0667,  0.1173,  0.0501],\n",
       "                      ...,\n",
       "                      [ 0.0940,  0.2433,  0.0708,  ..., -0.0504, -0.2593, -0.0340],\n",
       "                      [ 0.1070,  0.0626, -0.0330,  ...,  0.0595,  0.0929,  0.0036],\n",
       "                      [ 0.0433, -0.1201,  0.0780,  ...,  0.0312,  0.0339,  0.1490]])),\n",
       "             ('layer2.bias',\n",
       "              tensor([ 6.3138e-02,  1.2947e-01,  2.0548e-06, -7.9265e-02,  8.7728e-02,\n",
       "                       1.9693e-01, -7.0496e-02,  1.7459e-01,  1.2692e-01,  5.9111e-02,\n",
       "                       5.4189e-02,  2.0060e-01,  5.9653e-02, -5.4732e-02,  7.4344e-02,\n",
       "                       9.9629e-02, -5.5088e-02, -5.4428e-02,  1.0466e-01, -9.5524e-02,\n",
       "                       2.1197e-01, -6.4483e-02, -9.1942e-02, -1.1965e-01,  1.6091e-01,\n",
       "                      -8.7256e-02,  2.2085e-01,  4.7408e-02,  1.4413e-01,  1.8192e-01,\n",
       "                       5.0754e-02, -5.1678e-02, -9.7855e-02, -6.3957e-04, -2.7292e-02,\n",
       "                       1.9496e-01, -9.0403e-02,  1.0829e-01,  1.1909e-01,  2.2725e-02,\n",
       "                       5.7231e-02,  2.2260e-01,  7.5807e-02,  2.4932e-02, -8.1979e-03,\n",
       "                       1.7837e-01,  6.2512e-02, -1.0554e-01,  1.0209e-01, -4.0893e-02,\n",
       "                      -1.2387e-01,  6.1262e-02, -8.7062e-02, -7.2018e-02, -1.9004e-02,\n",
       "                       7.6847e-02, -2.6832e-02,  1.8247e-01, -2.2617e-02,  7.1025e-02,\n",
       "                      -8.3564e-02, -8.8139e-02,  1.0731e-01, -2.4809e-02,  7.7287e-02,\n",
       "                       5.2360e-02,  1.1463e-01, -8.6447e-02,  5.3323e-02, -6.6972e-03,\n",
       "                       1.3223e-01,  4.6195e-02,  1.5549e-01,  1.3349e-01,  9.1412e-02,\n",
       "                       5.2547e-02,  5.5083e-02, -2.4410e-03, -8.7060e-02,  6.2185e-02,\n",
       "                       2.6385e-02, -7.2018e-02, -1.0661e-02, -1.2268e-01, -7.8083e-02,\n",
       "                       1.0153e-01, -1.6177e-02, -5.5704e-02, -1.2511e-01,  2.4543e-02,\n",
       "                      -8.9496e-02,  2.2529e-01,  1.1736e-01,  3.0772e-02, -7.3083e-03,\n",
       "                       1.8485e-01,  1.1401e-01,  8.0980e-03,  8.0593e-02, -6.5494e-03,\n",
       "                      -2.4675e-02,  4.4232e-02,  7.7082e-02,  1.8283e-01,  5.6075e-02,\n",
       "                      -1.1253e-01,  4.4395e-02,  1.5240e-02,  7.4724e-02,  6.8421e-02,\n",
       "                       1.7918e-01, -3.9094e-02, -5.4107e-02,  2.2508e-03,  1.6333e-01,\n",
       "                      -7.7485e-02,  6.7161e-02, -1.6383e-02,  7.8805e-02, -1.2106e-01,\n",
       "                       7.0012e-02, -4.5820e-02,  8.6583e-02,  1.9455e-01,  1.9135e-01,\n",
       "                       1.5811e-01,  5.5864e-03, -5.2024e-03])),\n",
       "             ('layer3.weight',\n",
       "              tensor([[ 0.0073,  0.0510, -0.0524,  ...,  0.0568,  0.0039,  0.0160],\n",
       "                      [ 0.0373, -0.0915, -0.0485,  ...,  0.0052,  0.0724,  0.0494],\n",
       "                      [-0.0295,  0.0860,  0.0143,  ...,  0.0373, -0.0387, -0.0918],\n",
       "                      ...,\n",
       "                      [-0.0056, -0.0562,  0.0015,  ..., -0.1171, -0.0478,  0.0228],\n",
       "                      [ 0.0756, -0.0614,  0.0550,  ...,  0.0091,  0.1290,  0.0364],\n",
       "                      [ 0.0232,  0.1307,  0.0666,  ...,  0.1648,  0.0671,  0.0886]])),\n",
       "             ('layer3.bias',\n",
       "              tensor([-0.0155,  0.0494,  0.1302,  0.1111,  0.0373,  0.1610,  0.0372,  0.0513,\n",
       "                      -0.0788,  0.1312,  0.0845,  0.1267,  0.0189,  0.0394, -0.0116, -0.0694,\n",
       "                       0.0783,  0.0226, -0.0580,  0.1564,  0.0287,  0.0198,  0.1696,  0.0228,\n",
       "                       0.0076,  0.1087,  0.1514,  0.1159,  0.1454, -0.0474,  0.0166,  0.0039,\n",
       "                       0.1645,  0.1766,  0.0050,  0.0226, -0.0862, -0.0060, -0.0496,  0.0563,\n",
       "                      -0.0178,  0.0936,  0.0254,  0.0082,  0.1524,  0.0674, -0.0185, -0.0418,\n",
       "                       0.2372, -0.0124, -0.0191, -0.0164,  0.0229,  0.1891, -0.0388,  0.0337,\n",
       "                       0.0481, -0.0838, -0.0702, -0.0682,  0.0742, -0.0408, -0.0542,  0.1333])),\n",
       "             ('layer4.weight',\n",
       "              tensor([[ 1.1507e-01, -3.0941e-02,  2.1681e-01, -4.3334e-01, -1.6392e-01,\n",
       "                       -1.4336e-01,  3.3457e-02, -1.1063e-01,  5.9498e-02, -3.8358e-01,\n",
       "                        5.3121e-02, -6.9195e-02,  2.6103e-01, -3.6913e-01,  4.1260e-02,\n",
       "                        1.3074e-01,  1.5722e-01, -2.2193e-01, -1.2424e-03, -2.1030e-01,\n",
       "                       -1.3952e-01,  2.5636e-01,  3.4833e-01,  8.3407e-04, -1.1776e-01,\n",
       "                        2.0168e-01, -1.6209e-01,  2.5935e-01, -1.4489e-02, -1.6064e-01,\n",
       "                        1.4377e-01,  3.1618e-01, -2.7361e-02, -5.7168e-01, -5.9745e-02,\n",
       "                        2.9109e-01, -5.6882e-02, -9.4000e-02,  3.4174e-01, -2.2907e-01,\n",
       "                       -2.1546e-01,  5.5575e-02, -1.0912e-02,  9.4461e-02, -3.4309e-01,\n",
       "                        3.9994e-03,  3.5488e-04, -5.6530e-02, -2.1891e-01, -1.2839e-02,\n",
       "                       -1.6897e-01, -1.2948e-02, -1.6065e-01, -5.2565e-01,  4.5789e-01,\n",
       "                        4.7204e-01, -3.7807e-01,  6.1884e-02,  1.7005e-01, -5.5924e-03,\n",
       "                        1.0619e-01,  3.7069e-01,  3.8788e-01, -1.9951e-01],\n",
       "                      [-2.7564e-01,  1.4947e-03, -2.1500e-02,  5.4615e-01, -9.3771e-03,\n",
       "                       -3.2637e-02, -2.1254e-02, -8.1120e-02, -1.1200e-01,  2.0012e-03,\n",
       "                        7.2983e-02,  5.2298e-01, -2.7001e-01,  1.0911e-01, -9.3353e-02,\n",
       "                        1.0073e-01, -2.4343e-01,  2.8944e-01,  1.7876e-01,  4.4186e-01,\n",
       "                        4.5281e-01, -2.6100e-03, -5.1533e-01, -1.4434e-01,  6.7247e-03,\n",
       "                       -2.6518e-02,  7.4530e-02, -1.0972e-01,  2.0910e-01,  7.9710e-02,\n",
       "                       -7.9032e-02, -2.1083e-01, -4.2840e-01,  8.7939e-02, -2.4475e-01,\n",
       "                       -3.2975e-01,  1.0657e-01, -4.2475e-02, -1.5359e-01, -1.5890e-02,\n",
       "                       -3.4332e-01, -4.3599e-01,  1.8072e-01,  3.6982e-02,  2.9373e-01,\n",
       "                       -1.0811e-01, -9.1268e-02, -4.7997e-02,  1.2476e-01,  3.0530e-02,\n",
       "                        5.2710e-02, -2.9590e-01,  1.7462e-01,  6.4488e-01, -2.2378e-01,\n",
       "                       -3.4356e-01,  1.5089e-02, -7.5654e-02, -1.2345e-01,  2.7591e-03,\n",
       "                       -2.7754e-01, -9.4493e-02,  1.0936e-01, -3.2305e-02],\n",
       "                      [ 2.7397e-01, -5.8127e-02,  3.1709e-01, -8.6044e-02, -2.2748e-02,\n",
       "                        2.6629e-02,  7.2534e-02, -3.8967e-01, -3.4833e-03,  1.5966e-01,\n",
       "                       -1.6540e-01, -9.2463e-02,  2.6418e-01, -3.4123e-01, -1.9982e-02,\n",
       "                       -5.0971e-02, -2.1292e-01,  2.5502e-01, -1.0383e-01, -2.2667e-01,\n",
       "                        2.2786e-01,  3.1834e-01, -3.6446e-01, -5.5779e-02,  3.3748e-02,\n",
       "                       -1.7642e-01, -4.1163e-01,  2.4728e-01,  4.5068e-01,  1.3256e-01,\n",
       "                       -7.9260e-02,  4.3626e-02,  1.3703e-01, -3.6277e-01,  3.3625e-01,\n",
       "                       -1.5763e-01, -9.7655e-02, -6.2735e-02,  2.4929e-01, -2.2039e-01,\n",
       "                        2.8554e-01, -1.1658e-01, -2.9920e-01,  4.7146e-02,  8.2963e-02,\n",
       "                       -7.7672e-02, -5.5628e-02, -1.4833e-02,  4.1871e-02, -1.5856e-01,\n",
       "                        4.8805e-01,  6.4429e-02, -3.1543e-02,  3.5321e-01, -1.5007e-01,\n",
       "                        5.2167e-02,  7.5538e-02, -7.0398e-02,  2.3024e-01,  9.9592e-02,\n",
       "                        2.1176e-01,  5.5816e-02, -9.5233e-02, -3.2670e-01],\n",
       "                      [ 1.7077e-01, -6.1573e-02,  9.5297e-02,  1.2029e-01, -2.4675e-01,\n",
       "                       -4.8159e-02,  1.9300e-01,  1.9110e-01,  1.1127e-02, -2.8902e-01,\n",
       "                       -5.5217e-02, -4.1269e-01, -1.9217e-02,  6.7157e-01,  8.5330e-04,\n",
       "                       -4.2902e-02,  1.6545e-01, -7.4569e-03,  1.9117e-01, -3.4940e-01,\n",
       "                       -4.5449e-01, -2.4974e-01, -8.9908e-02,  4.9510e-01, -1.6611e-02,\n",
       "                       -8.1674e-02,  3.1811e-01, -4.7534e-02, -1.1654e-01, -4.7059e-02,\n",
       "                        1.5723e-03,  4.8753e-02, -3.4672e-01,  1.5263e-02,  3.2673e-01,\n",
       "                        1.2169e-01, -1.0653e-01,  4.4213e-02, -2.4894e-01, -1.6656e-01,\n",
       "                        1.3993e-01, -2.8080e-01,  6.2507e-02, -2.6582e-01,  1.0895e-01,\n",
       "                       -1.8091e-01, -5.6234e-02, -1.1662e-01, -2.1378e-01, -1.7950e-01,\n",
       "                        2.8389e-01, -1.9899e-01,  1.9639e-01,  2.2806e-01,  1.9457e-01,\n",
       "                       -1.7618e-01,  4.5285e-01,  1.5357e-03, -1.6711e-01, -1.1249e-01,\n",
       "                       -2.4737e-01, -8.1786e-02, -3.5384e-01,  2.6779e-01],\n",
       "                      [-1.2955e-01,  2.7219e-01,  5.0242e-02,  2.1434e-02,  1.3534e-01,\n",
       "                        1.7923e-01, -1.8574e-01, -2.5244e-01, -8.1295e-02,  6.1349e-01,\n",
       "                        2.8764e-01,  1.2417e-02, -4.6610e-01, -1.8443e-01,  1.2269e-01,\n",
       "                       -2.0375e-02,  1.8246e-01, -5.0378e-02, -1.1480e-01,  2.7053e-01,\n",
       "                        1.5887e-01, -2.3638e-01, -2.9873e-01, -2.2359e-01, -5.6750e-02,\n",
       "                        3.7396e-01, -1.9980e-01,  2.3558e-02, -1.6668e-01, -4.7999e-02,\n",
       "                        1.2096e-01, -4.1882e-01,  5.6107e-01,  3.0510e-01, -3.8068e-01,\n",
       "                        1.9485e-01,  1.2036e-01,  5.0262e-02, -1.5175e-01,  2.6610e-01,\n",
       "                        1.0468e-01,  4.2252e-01, -1.0276e-01, -2.6570e-01, -3.3244e-01,\n",
       "                        3.8772e-02,  5.1954e-02, -4.3390e-02,  4.9264e-01,  2.7681e-01,\n",
       "                       -1.0634e-01,  6.3507e-02, -4.1070e-01,  7.5784e-02, -3.1753e-01,\n",
       "                       -1.7384e-01,  1.4356e-01,  1.0562e-02, -1.9642e-01, -1.3128e-01,\n",
       "                       -2.4018e-01, -1.8587e-01,  5.3046e-02, -1.5809e-01],\n",
       "                      [ 7.2572e-03,  1.2966e-01,  3.8685e-01, -1.7573e-01, -6.1418e-02,\n",
       "                        8.4403e-05,  1.6650e-01,  8.3080e-02,  1.2575e-01, -2.3532e-02,\n",
       "                       -3.0172e-02, -4.6195e-02, -1.7641e-01,  2.0498e-01,  1.0699e-01,\n",
       "                       -7.4246e-02, -1.1355e-01,  1.1832e-02, -2.0894e-01,  8.1625e-02,\n",
       "                       -9.3785e-02, -3.6495e-01,  1.1608e+00, -8.7047e-02, -3.7837e-02,\n",
       "                        6.0107e-04,  5.4161e-01,  2.1379e-02, -6.0502e-02, -4.1010e-02,\n",
       "                        1.1512e-02, -1.6265e-01,  8.7440e-03,  2.6245e-01,  5.3553e-03,\n",
       "                       -1.5950e-01,  7.0067e-02,  3.5355e-02, -2.6702e-01, -5.1523e-01,\n",
       "                       -4.6127e-01,  1.7938e-01,  5.0106e-01,  1.1820e-01,  1.1820e-01,\n",
       "                        1.8896e-01,  5.9084e-03,  1.1242e-01, -3.6453e-01, -8.5384e-02,\n",
       "                       -2.1700e-01, -1.1508e-01,  3.7660e-01, -8.8809e-02,  1.1879e-01,\n",
       "                       -3.3283e-01, -1.6853e-01,  4.1575e-02, -3.9318e-01,  5.0206e-02,\n",
       "                       -1.5990e-01, -6.4640e-03, -1.8577e-01, -1.4052e-01],\n",
       "                      [-3.3609e-01,  3.1877e-02, -2.2915e-01, -2.4608e-02,  3.8040e-01,\n",
       "                       -2.1564e-02, -6.8341e-02,  4.9494e-01,  1.6610e-02,  3.9263e-01,\n",
       "                       -1.7590e-01, -1.8612e-01, -2.8261e-01, -3.6877e-01,  1.0761e-01,\n",
       "                       -1.0648e-01, -3.9727e-01,  2.4814e-01, -1.3453e-01,  2.4098e-01,\n",
       "                        1.8765e-02, -4.1405e-02,  2.1928e-01, -3.9436e-01,  6.1444e-02,\n",
       "                        2.4031e-01, -2.7306e-01,  3.1762e-01,  4.4464e-01, -7.3960e-03,\n",
       "                       -1.3694e-01, -3.7332e-02,  3.7332e-01, -3.0472e-01, -2.9363e-01,\n",
       "                        1.7244e-02, -5.5126e-03, -1.0088e-01,  3.0015e-01, -5.6954e-03,\n",
       "                       -3.4664e-01, -3.4164e-01,  2.1970e-01,  3.1235e-01, -2.4869e-01,\n",
       "                       -2.4765e-01, -7.7286e-02,  6.6429e-02, -2.0943e-01,  1.2526e-01,\n",
       "                       -1.9103e-01,  3.1399e-01,  8.8537e-02, -4.3423e-01,  3.5478e-01,\n",
       "                       -1.9480e-01, -1.5246e-01,  4.7001e-02,  2.2434e-01,  9.0841e-02,\n",
       "                       -9.7967e-02,  3.6313e-02, -1.1315e-01, -3.3782e-01],\n",
       "                      [ 5.3926e-04, -8.8702e-02, -2.7545e-01, -4.4241e-02, -6.4036e-02,\n",
       "                        5.5049e-01,  1.1461e-01, -8.7132e-03,  1.2201e-01, -5.3009e-01,\n",
       "                       -2.7586e-01,  1.6813e-01,  2.1277e-01, -1.3750e-01, -1.0799e-01,\n",
       "                       -2.5959e-02, -4.5605e-01,  3.3739e-02, -1.0553e-01,  2.0623e-01,\n",
       "                        1.0324e-01,  1.2777e-01, -5.6960e-01, -1.9880e-01, -6.1670e-02,\n",
       "                        1.2554e-01, -2.2306e-01,  2.5853e-02, -1.2702e-01,  2.2594e-01,\n",
       "                        4.4782e-02,  3.6056e-01, -3.5596e-01,  2.9110e-01, -1.8615e-01,\n",
       "                       -1.4251e-01,  7.9348e-02, -7.5732e-02, -7.6805e-02, -2.2683e-01,\n",
       "                        3.4731e-01,  2.1530e-01, -3.4529e-02, -2.2210e-02,  4.7613e-01,\n",
       "                        2.9519e-01,  2.4295e-02, -3.8334e-02,  4.7654e-01, -2.2807e-01,\n",
       "                        3.2089e-01, -3.7396e-01, -3.7626e-01,  1.8982e-01, -2.0423e-01,\n",
       "                        2.8732e-01, -3.1817e-01, -4.6262e-02, -8.0767e-03, -3.2947e-02,\n",
       "                        6.9245e-03,  3.5743e-01, -6.6829e-02,  4.9095e-01],\n",
       "                      [-2.0638e-01, -2.7655e-02, -2.3864e-01,  2.0493e-01,  2.9545e-01,\n",
       "                       -4.2490e-01, -5.3018e-02,  4.5191e-02, -6.2172e-02,  6.2445e-03,\n",
       "                        1.2843e-01, -4.1024e-01,  6.6205e-02,  6.4831e-02,  2.1148e-02,\n",
       "                       -3.6494e-02,  5.3001e-01,  1.9367e-01,  3.5357e-01, -3.7317e-01,\n",
       "                        3.6395e-01,  3.4125e-01,  2.4862e-01, -4.6243e-02,  7.2948e-02,\n",
       "                       -2.2919e-01,  1.7745e-01, -4.4338e-01, -3.5226e-01, -1.6763e-01,\n",
       "                       -1.7712e-02,  2.1045e-01,  3.1457e-02,  1.1987e-01, -2.3296e-02,\n",
       "                        7.3525e-02,  3.1632e-02, -2.7907e-02, -1.1554e-01,  4.5367e-01,\n",
       "                        2.8928e-02,  8.9641e-02, -3.6316e-01, -8.6951e-02, -2.5380e-01,\n",
       "                       -2.7395e-01, -3.2548e-02, -9.8710e-02, -5.3078e-01, -1.6884e-01,\n",
       "                       -3.7880e-03,  3.6899e-01,  5.4216e-01, -3.1566e-02, -3.7946e-01,\n",
       "                       -2.2174e-02,  2.8179e-01,  2.1331e-02,  1.3783e-01, -7.1328e-02,\n",
       "                        2.2719e-01,  1.2047e-01, -1.6674e-01, -2.6824e-01],\n",
       "                      [ 3.3077e-02, -1.8547e-02, -2.6623e-01, -3.2928e-01, -1.0578e-01,\n",
       "                       -1.1464e-01, -7.2337e-03, -6.2699e-03,  1.2989e-02, -2.0667e-02,\n",
       "                        3.7528e-01,  2.5869e-01,  2.6728e-01, -3.2050e-02,  8.6618e-02,\n",
       "                        6.6523e-02,  2.4152e-01, -2.2996e-01,  1.4667e-01, -1.5850e-01,\n",
       "                       -3.7669e-01, -1.3292e-01,  2.0242e-02,  1.9857e-01,  9.2602e-02,\n",
       "                       -5.0964e-01,  4.5275e-01,  1.1328e-01, -3.5546e-01, -2.3301e-01,\n",
       "                       -1.5788e-01, -2.8404e-01,  1.7266e-01,  5.2581e-01,  2.7172e-01,\n",
       "                        2.1938e-01,  4.0690e-02,  8.1221e-02,  5.3629e-02,  4.5510e-01,\n",
       "                        3.4609e-02,  1.2472e-01,  1.1017e-01, -1.7671e-01, -1.5822e-01,\n",
       "                        6.9920e-02,  5.6993e-02,  5.9815e-02,  4.5219e-01,  6.1807e-02,\n",
       "                       -4.1738e-01, -3.2895e-01,  6.4125e-02, -3.8972e-01, -1.0251e-01,\n",
       "                        2.7852e-01, -1.5954e-01, -1.6319e-02, -1.0017e-01,  2.3361e-02,\n",
       "                        2.3639e-01, -4.0582e-01,  1.6187e-01,  5.2703e-01]])),\n",
       "             ('layer4.bias',\n",
       "              tensor([-0.1348,  0.1377,  0.0795, -0.0409, -0.0084,  0.2218, -0.0650, -0.0622,\n",
       "                      -0.2315,  0.0022]))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load('mnist-logistic.pth'))\n",
    "model2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.09204165637493134, 'val_acc': 0.97265625}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "result = evaluate(model2, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
